{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1660882519921,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "KoC-hLN4Oliv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Sequence\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from flax import linen as nn\n",
    "from jax import jvp, value_and_grad\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(alpha):\n",
    "    phi = jnp.exp(-1 * alpha**2)\n",
    "    return phi\n",
    "\n",
    "\n",
    "def linear(alpha):\n",
    "    return alpha\n",
    "\n",
    "\n",
    "# Define the RBF module using FLAX\n",
    "class RBF(nn.Module):\n",
    "\n",
    "    out_features: int\n",
    "    basis_func: callable\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, input):\n",
    "        # Initialize learnable parameters\n",
    "        centres = self.param(\"centres\", nn.initializers.normal(), (self.out_features, 1))\n",
    "        log_sigmas = self.param(\"log_sigmas\", nn.initializers.constant(0.001), (self.out_features,))\n",
    "\n",
    "        # Compute distances\n",
    "        x = jnp.expand_dims(input, axis=1)\n",
    "        c = jnp.expand_dims(centres, axis=0)\n",
    "        distances = jnp.sqrt(jnp.sum((x - c) ** 2, axis=-1)) / jnp.exp(log_sigmas)\n",
    "\n",
    "        # Apply radial basis function\n",
    "        return self.basis_func(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1660882524486,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "3lmf86_ON_5N"
   },
   "outputs": [],
   "source": [
    "# forward function\n",
    "class CPPINN(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    # bases = [bases_x,bases_y,bases_z]\n",
    "    @nn.compact\n",
    "    def __call__(self, x, y, z):\n",
    "        inputs, outputs = [x, y, z], []\n",
    "        init = nn.initializers.xavier_normal()\n",
    "        for X in inputs:\n",
    "            for fs in self.features[:-1]:\n",
    "                X = nn.Dense(fs, kernel_init=init)(X)\n",
    "                X = nn.activation.tanh(X)\n",
    "            X = nn.Dense(self.features[-1], kernel_init=init)(X)\n",
    "\n",
    "            outputs += [jnp.transpose(X, (1, 0))]\n",
    "\n",
    "        xy = jnp.einsum(\"fx, fy->fxy\", outputs[0], outputs[1])\n",
    "        return jnp.einsum(\"fxy, fz->xyz\", xy, outputs[-1])\n",
    "\n",
    "\n",
    "class TTPINN(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    # bases = [bases_x,bases_y,bases_z]\n",
    "    @nn.compact\n",
    "    def __call__(self, x, y, z):\n",
    "        inputs, outputs = [x, y, z], []\n",
    "        init = nn.initializers.xavier_uniform()\n",
    "        for i, X in enumerate(inputs):\n",
    "            for fs in self.features[:-1]:\n",
    "                X = nn.Dense(fs, kernel_init=init)(X)\n",
    "                X = nn.activation.tanh(X)\n",
    "            if i == 0:\n",
    "                X = nn.DenseGeneral((self.features[-1], self.features[-1]), kernel_init=init)(X)\n",
    "\n",
    "            else:\n",
    "                X = nn.Dense(self.features[-1], kernel_init=init)(X)\n",
    "            outputs += [X]\n",
    "\n",
    "        # mid = jnp.einsum('ij,kj->ikj', outputs[1][:self.features[-1]], outputs[1][self.features[-1]:])\n",
    "        # print(mid.shape)\n",
    "        # mid = jnp.einsum('fx,ky->fyk',outputs[0],outputs[1])\n",
    "        # xyz = jnp.einsum('fx, fy,fz->xyz', outputs[0], outputs[1],outputs[-1])\n",
    "        return jnp.einsum(\"xfk,yf,zk->xyz\", outputs[0], outputs[1], outputs[-1])\n",
    "\n",
    "\n",
    "class TuckerPINN(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    def setup(self):\n",
    "        # Initialize learnable parameters\n",
    "        # self.centres = self.param('centres', nn.initializers.uniform(1.01), (self.out_features, 1))\n",
    "        self.core = self.param(\"core\", nn.initializers.orthogonal(), (self.features[-1], self.features[-1], self.features[-1]))\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, y, z):\n",
    "        inputs, outputs = [x, y, z], []\n",
    "        init = nn.initializers.xavier_normal()\n",
    "        for X in inputs:\n",
    "            for fs in self.features[:-1]:\n",
    "                X = nn.Dense(fs, kernel_init=init)(X)\n",
    "                X = nn.activation.tanh(X)\n",
    "            X = nn.Dense(self.features[-1], kernel_init=init)(X)\n",
    "\n",
    "            outputs += [jnp.transpose(X, (1, 0))]\n",
    "            # mid = jnp.einsum(\"fx,fy->fxy\",outputs[0],outputs[1])\n",
    "        return jnp.einsum(\"klm,kx,ly,mz->xyz\", self.core, outputs[0], outputs[1], outputs[-1])\n",
    "\n",
    "\n",
    "class RBFPINN(nn.Module):\n",
    "    # features: Sequence[int]\n",
    "    out_features: int\n",
    "    basis_func: callable\n",
    "    centers_x = jnp.linspace(-0.1, 10.1, 64).reshape((64, 1))\n",
    "    centers_y = jnp.linspace(-1.1, 1.1, 64).reshape((64, 1))\n",
    "    centers_z = jnp.linspace(-1.1, 1.1, 64).reshape((64, 1))\n",
    "    all_centres = [centers_x, centers_y, centers_z]\n",
    "\n",
    "    def setup(self):\n",
    "        # Initialize learnable parameters\n",
    "        # self.centres = self.param('centres', nn.initializers.uniform(1.01), (self.out_features, 1))\n",
    "        self.log_sigmas = self.param(\"log_sigmas\", nn.initializers.constant(0.0), (self.out_features,))\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, y, z):\n",
    "        # Normalize input data\n",
    "        # x = self.normalize(x,0,10)\n",
    "        # print(x)\n",
    "        # y = self.normalize(y,-1,2)\n",
    "        # z = self.normalize(z,-1,2)\n",
    "\n",
    "        inputs, outputs = [x, y, z], []\n",
    "        init = nn.initializers.xavier_normal()\n",
    "        for X, centres in zip(inputs, self.all_centres):\n",
    "            # Compute distances\n",
    "            x = jnp.expand_dims(X, axis=1)\n",
    "            c = jnp.expand_dims(centres, axis=0)\n",
    "            distances = jnp.sqrt(jnp.sum((x - c) ** 2, axis=-1)) / jnp.exp(self.log_sigmas)\n",
    "            # Apply radial basis function\n",
    "            X = self.basis_func(distances)\n",
    "            # X = nn.Dense(self.out_features, kernel_init=init)(X)\n",
    "            print(X)\n",
    "            outputs += [jnp.transpose(X, (1, 0))]\n",
    "        xy = jnp.einsum(\"fx, fy->fxy\", outputs[0], outputs[-1])\n",
    "        return jnp.einsum(\"fxy, fz->xyz\", xy, outputs[1])\n",
    "\n",
    "    def normalize(self, data, mean, std):\n",
    "        # Normalize data\n",
    "        # mean = jnp.mean(data, axis=0)\n",
    "        # std = jnp.std(data, axis=0)\n",
    "        normalized_data = (data - mean) / std\n",
    "        return normalized_data\n",
    "\n",
    "\n",
    "# hessian-vector product\n",
    "def hvp_fwdfwd(f, primals, tangents, return_primals=False):\n",
    "    g = lambda primals: jvp(f, (primals,), tangents)[1]\n",
    "    primals_out, tangents_out = jvp(g, primals, tangents)\n",
    "    if return_primals:\n",
    "        return primals_out, tangents_out\n",
    "    else:\n",
    "        return tangents_out\n",
    "\n",
    "\n",
    "# loss function\n",
    "def spinn_loss_klein_gordon3d(apply_fn, *train_data):\n",
    "    def residual_loss(params, t, x, y, source_term):\n",
    "        # calculate u\n",
    "        u = apply_fn(params, t, x, y)\n",
    "        # tangent vector dx/dx\n",
    "        # assumes t, x, y have same shape (very important)\n",
    "        v = jnp.ones(t.shape)\n",
    "        # 2nd derivatives of u\n",
    "        utt = hvp_fwdfwd(lambda t: apply_fn(params, t, x, y), (t,), (v,))\n",
    "        uxx = hvp_fwdfwd(lambda x: apply_fn(params, t, x, y), (x,), (v,))\n",
    "        uyy = hvp_fwdfwd(lambda y: apply_fn(params, t, x, y), (y,), (v,))\n",
    "        return jnp.mean((utt - uxx - uyy + u**2 - source_term) ** 2)\n",
    "\n",
    "    def initial_loss(params, t, x, y, u):\n",
    "        return jnp.mean((apply_fn(params, t, x, y) - u) ** 2)\n",
    "\n",
    "    def boundary_loss(params, t, x, y, u):\n",
    "        loss = 0.0\n",
    "        for i in range(4):\n",
    "            loss += (1 / 4.0) * jnp.mean((apply_fn(params, t[i], x[i], y[i]) - u[i]) ** 2)\n",
    "        return loss\n",
    "\n",
    "    # unpack data\n",
    "    tc, xc, yc, uc, ti, xi, yi, ui, tb, xb, yb, ub = train_data\n",
    "\n",
    "    # isolate loss function from redundant arguments\n",
    "    fn = lambda params: residual_loss(params, tc, xc, yc, uc) + initial_loss(params, ti, xi, yi, ui) + boundary_loss(params, tb, xb, yb, ub)\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "# optimizer step function\n",
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def update_model(optim, gradient, params, state):\n",
    "    updates, state = optim.update(gradient, state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3OErz7bN_5O"
   },
   "source": [
    "## 2. Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1660882526334,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "VVY7wtfBN_5O"
   },
   "outputs": [],
   "source": [
    "# 2d time-dependent klein-gordon exact u\n",
    "def _klein_gordon3d_exact_u(t, x, y):\n",
    "    return (x + y) * jnp.cos(2 * t) + (x * y) * jnp.sin(2 * t)\n",
    "\n",
    "\n",
    "# 2d time-dependent klein-gordon source term\n",
    "def _klein_gordon3d_source_term(t, x, y):\n",
    "    u = _klein_gordon3d_exact_u(t, x, y)\n",
    "    return u**2 - 4 * u\n",
    "\n",
    "\n",
    "# train data\n",
    "def spinn_train_generator_klein_gordon3d(nc, key):\n",
    "    keys = jax.random.split(key, 3)\n",
    "    # collocation points\n",
    "    tc = jax.random.uniform(keys[0], (nc, 1), minval=0.0, maxval=10.0)\n",
    "    xc = jax.random.uniform(keys[1], (nc, 1), minval=-1.0, maxval=1.0)\n",
    "    yc = jax.random.uniform(keys[2], (nc, 1), minval=-1.0, maxval=1.0)\n",
    "    tc_mesh, xc_mesh, yc_mesh = jnp.meshgrid(tc.ravel(), xc.ravel(), yc.ravel(), indexing=\"ij\")\n",
    "    uc = _klein_gordon3d_source_term(tc_mesh, xc_mesh, yc_mesh)\n",
    "    # initial points\n",
    "    ti = jnp.zeros((1, 1))\n",
    "    xi = xc\n",
    "    yi = yc\n",
    "    ti_mesh, xi_mesh, yi_mesh = jnp.meshgrid(ti.ravel(), xi.ravel(), yi.ravel(), indexing=\"ij\")\n",
    "    ui = _klein_gordon3d_exact_u(ti_mesh, xi_mesh, yi_mesh)\n",
    "    # boundary points (hard-coded)\n",
    "    tb = [tc, tc, tc, tc]\n",
    "    xb = [jnp.array([[-1.0]]), jnp.array([[1.0]]), xc, xc]\n",
    "    yb = [yc, yc, jnp.array([[-1.0]]), jnp.array([[1.0]])]\n",
    "    ub = []\n",
    "    for i in range(4):\n",
    "        tb_mesh, xb_mesh, yb_mesh = jnp.meshgrid(tb[i].ravel(), xb[i].ravel(), yb[i].ravel(), indexing=\"ij\")\n",
    "        ub += [_klein_gordon3d_exact_u(tb_mesh, xb_mesh, yb_mesh)]\n",
    "    return tc, xc, yc, uc, ti, xi, yi, ui, tb, xb, yb, ub\n",
    "\n",
    "\n",
    "# test data\n",
    "def spinn_test_generator_klein_gordon3d(nc_test):\n",
    "    t = jnp.linspace(0, 10, nc_test)\n",
    "    x = jnp.linspace(-1, 1, nc_test)\n",
    "    y = jnp.linspace(-1, 1, nc_test)\n",
    "    t = jax.lax.stop_gradient(t)\n",
    "    x = jax.lax.stop_gradient(x)\n",
    "    y = jax.lax.stop_gradient(y)\n",
    "    tm, xm, ym = jnp.meshgrid(t, x, y, indexing=\"ij\")\n",
    "    u_gt = _klein_gordon3d_exact_u(tm, xm, ym)\n",
    "    t = t.reshape(-1, 1)\n",
    "    x = x.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    return t, x, y, u_gt, tm, xm, ym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEWeH3ZFN_5P"
   },
   "source": [
    "## 3. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1660882528274,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "cLX1oaDUN_5P"
   },
   "outputs": [],
   "source": [
    "def relative_l2(u, u_gt):\n",
    "    return jnp.linalg.norm(u - u_gt) / jnp.linalg.norm(u_gt)\n",
    "\n",
    "\n",
    "def plot_klein_gordon3d(t, x, y, u):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    im = ax.scatter(t, x, y, c=u, s=0.5, cmap=\"viridis\")\n",
    "    # im2 = ax.scatter(0,0,0,c=-1,s=100,cmap='seismic')\n",
    "    ax.set_title(\"U(t, x, y)\", fontsize=20)\n",
    "    ax.set_xlabel(\"t\", fontsize=18, labelpad=10)\n",
    "    ax.set_ylabel(\"x\", fontsize=18, labelpad=10)\n",
    "    ax.set_zlabel(\"y\", fontsize=18, labelpad=10)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q3WgLq_N_5P"
   },
   "source": [
    "## 4. Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1660882530315,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "VHtJazHuN_5Q"
   },
   "outputs": [],
   "source": [
    "def main(mode, NC, NI, NB, NC_TEST, SEED, LR, EPOCHS, N_LAYERS, FEATURES, LOG_ITER):\n",
    "    # force jax to use one device\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "    # random key\n",
    "    key = jax.random.PRNGKey(SEED)\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "\n",
    "    # feature sizes\n",
    "    feat_sizes = tuple(FEATURES for _ in range(N_LAYERS))\n",
    "\n",
    "    # model = RBFPINN(FEATURES,linear)\n",
    "    # make & init model\n",
    "    if mode == \"CPPINN\":\n",
    "        model = CPPINN(feat_sizes)\n",
    "    elif mode == \"TTPINN\":\n",
    "        model = TTPINN(feat_sizes)\n",
    "    elif mode == \"TuckerPINN\":\n",
    "        model = TuckerPINN(feat_sizes)\n",
    "    params = model.init(subkey, jax.random.uniform(key, (NC, 1)), jax.random.uniform(key, (NC, 1)), jax.random.uniform(key, (NC, 1)))\n",
    "    # optimizer\n",
    "    optim = optax.adam(LR)\n",
    "    state = optim.init(params)\n",
    "\n",
    "    # dataset\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "    train_data = spinn_train_generator_klein_gordon3d(NC, subkey)\n",
    "    t, x, y, u_gt, tm, xm, ym = spinn_test_generator_klein_gordon3d(NC_TEST)\n",
    "    # print(t,x,y)\n",
    "    logger = []\n",
    "\n",
    "    # forward & loss function\n",
    "    apply_fn = jax.jit(model.apply)\n",
    "    loss_fn = spinn_loss_klein_gordon3d(apply_fn, *train_data)\n",
    "\n",
    "    @jax.jit\n",
    "    def train_one_step(params, state):\n",
    "        # compute loss and gradient\n",
    "        loss, gradient = value_and_grad(loss_fn)(params)\n",
    "        # update state\n",
    "        params, state = update_model(optim, gradient, params, state)\n",
    "        return loss, params, state\n",
    "\n",
    "    start = time.time()\n",
    "    pbar = tqdm.tqdm(total=EPOCHS)\n",
    "    error = np.nan\n",
    "\n",
    "    for iters in range(1, EPOCHS + 1):\n",
    "        # single run\n",
    "        loss, params, state = train_one_step(params, state)\n",
    "\n",
    "        if iters % LOG_ITER == 0 or iters == 1:\n",
    "            u = apply_fn(params, t, x, y)\n",
    "            error = relative_l2(u, u_gt)\n",
    "            # print(f\"Epoch: {iters}/{EPOCHS} --> loss: {loss:.8f}, error: {error:.8f}\")\n",
    "            logger.append([iters, loss, error])\n",
    "\n",
    "            # print(\"Solution:\")\n",
    "            # u = apply_fn(params, t, x, y)\n",
    "            # plot_klein_gordon3d(tm, xm, ym, u)\n",
    "\n",
    "        pbar.set_postfix({\"loss\": f\"{loss:0.8f}\", \"error\": f\"{error:0.8f}\"}, refresh=False)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Runtime: {((end-start)/EPOCHS*1000):.2f} ms/iter.\")\n",
    "\n",
    "    # print(\"Solution:\")\n",
    "    # u = apply_fn(params, t, x, y)\n",
    "    # plot_klein_gordon3d(tm, xm, ym, u)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = Path(\"results\")\n",
    "out_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCdzoogAN_5Q"
   },
   "source": [
    "## 5. Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 159365,
     "status": "ok",
     "timestamp": 1660882219515,
     "user": {
      "displayName": "Seungtae Nam",
      "userId": "06693906068580730486"
     },
     "user_tz": -540
    },
    "id": "j-DGXwqYN_5Q",
    "outputId": "2a4e9df1-378f-460e-cb99-70613412a8da",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points = 64\n",
    "\n",
    "for model in [\"CPPINN\", \"TTPINN\", \"TuckerPINN\"]:\n",
    "    model_folder = out_folder / model\n",
    "    model_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    for rank in [8, 16, 32]:\n",
    "        model_folder_rank = model_folder / f\"Rank_{rank:03d}\"\n",
    "        model_folder_rank.mkdir(exist_ok=True)\n",
    "\n",
    "        for run in range(10):\n",
    "            print(f\"Running {model} with rank {rank} and run {run}\")\n",
    "            logs = main(mode=model, NC=points, NI=points, NB=points, NC_TEST=32, SEED=444444 + run, LR=1e-3, EPOCHS=80000, N_LAYERS=4, FEATURES=rank, LOG_ITER=5000)\n",
    "            out_file = model_folder_rank / f\"{model}-Rank_{rank:02d}-Points_{points:02d}-run_{run:02d}.csv\"\n",
    "            pd.DataFrame(logs, columns=[\"Iter\", \"Loss\", \"Error\"]).to_csv(out_file, index=False, float_format=\"%.16f\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "spinn_demo.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "TD4PINN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
